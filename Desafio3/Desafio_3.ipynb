{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712841ac",
   "metadata": {},
   "source": [
    "# Modelo de lenguaje con tokenización por caracteres\n",
    "\n",
    "## Consigna\n",
    "Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
    "\n",
    "Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
    "\n",
    "Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
    "\n",
    "Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
    "\n",
    "## Sugerencias\n",
    "Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
    "\n",
    "Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU. rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7348dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
    "from keras.models import Model, Sequential\n",
    "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
    "from tensorflow.keras.utils import pad_sequences # se utilizará para padding\n",
    "\n",
    "# descargar de textos.info\n",
    "import urllib.request\n",
    "\n",
    "# Para leer y parsear el texto en HTML de wikipedia\n",
    "import bs4 as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339979cb",
   "metadata": {},
   "source": [
    "En este caso, voy a utilizar el Martin fierro de José Hernandez como corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54625c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_html = urllib.request.urlopen('https://www.textos.info/jose-hernandez/el-gaucho-martin-fierro/ebook')\n",
    "raw_html = raw_html.read()\n",
    "\n",
    "# Parsear artículo, 'lxml' es el parser a utilizar\n",
    "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
    "\n",
    "# Encontrar todos los párrafos del HTML (bajo el tag <p>)\n",
    "# y tenerlos disponible como lista\n",
    "article_paragraphs = article_html.find_all('p')\n",
    "\n",
    "article_text = ''\n",
    "\n",
    "for para in article_paragraphs:\n",
    "    article_text += para.text + ' '\n",
    "\n",
    "# pasar todo el texto a minúscula\n",
    "article_text = article_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4f45031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63273"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# en article text se encuentra el texto de todo el libro\n",
    "len(article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeac98c",
   "metadata": {},
   "source": [
    "Separo los caracteres del corpus en un set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc1f743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_vocab = set(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76c3e1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la longitud de vocabulario de caracteres es:\n",
    "len(chars_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5683f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
    "# El diccionario `char2idx` servirá como tokenizador.\n",
    "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
    "idx2char = {v: k for k,v in char2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb44eb4",
   "metadata": {},
   "source": [
    "## Tokenizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53954c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizamos el texto completo\n",
    "tokenized_text = [char2idx[ch] for ch in article_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e39bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionamos el tamaño de contexto\n",
    "max_context_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be9dd020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separaremos el dataset entre entrenamiento y validación.\n",
    "# `p_val` será la proporción del corpus que se reservará para validación\n",
    "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
    "p_val = 0.1\n",
    "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5432126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
    "train_text = tokenized_text[:-num_val*max_context_size]\n",
    "val_text = tokenized_text[-num_val*max_context_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "127fa590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [24],\n",
       " [4, 43],\n",
       " [32, 43, 7],\n",
       " [29, 45, 51, 10],\n",
       " [33, 53, 29, 6, 24],\n",
       " [48, 11, 3, 52, 24, 4],\n",
       " [43, 48, 33, 9, 51, 29, 33],\n",
       " [10, 43, 48, 33, 24, 33, 10, 24],\n",
       " [29, 48, 12, 43, 33, 52, 24, 10, 43]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]\n",
    "tokenized_sentences_val[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23166244",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]\n",
    "\n",
    "X = np.array(tokenized_sentences_train[:-1])\n",
    "y = np.array(tokenized_sentences_train[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc71c6e9",
   "metadata": {},
   "source": [
    "Comprobamos que tengan el mismo tamaño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07e9b273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56773, 100) (56773, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3b1c8",
   "metadata": {},
   "source": [
    "Comprobamos que el target está corrido una posición respecto de X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ad602fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33 24  9 51 15 33 12 29 33 52]\n",
      "   [24  9 51 15 33 12 29 33 52 43]\n"
     ]
    }
   ],
   "source": [
    "print(X[0,:10])\n",
    "print(f\"   {y[0,:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854a1f87",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5957028d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\anaconda3\\envs\\ia_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonat\\anaconda3\\envs\\ia_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:100: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,520</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">328,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,135</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m3,520\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m328,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m525,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m55\u001b[0m)        │        \u001b[38;5;34m14,135\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">871,671</span> (3.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m871,671\u001b[0m (3.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">871,671</span> (3.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m871,671\u001b[0m (3.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "vocab_size = len(chars_vocab)\n",
    "\n",
    "#model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
    "#model.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
    "\n",
    "model.add(Embedding(vocab_size, 64, input_length=max_context_size, input_shape=(max_context_size,)))\n",
    "model.add(LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "#model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a1af8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PplCallback(keras.callbacks.Callback):\n",
    "    '''\n",
    "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
    "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
    "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
    "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
    "    si la perplejidad no mejora después de `patience` epochs.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, val_data, history_ppl,patience=5):\n",
    "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
    "      # mediremos la perplejidad\n",
    "      self.val_data = val_data\n",
    "\n",
    "      self.target = []\n",
    "      self.padded = []\n",
    "\n",
    "      count = 0\n",
    "      self.info = []\n",
    "      self.min_score = np.inf\n",
    "      self.patience_counter = 0\n",
    "      self.patience = patience\n",
    "\n",
    "      # nos movemos en todas las secuencias de los datos de validación\n",
    "      for seq in self.val_data:\n",
    "\n",
    "        len_seq = len(seq)\n",
    "        # armamos todas las subsecuencias\n",
    "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
    "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
    "\n",
    "        if len(subseq)!=0:\n",
    "\n",
    "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
    "\n",
    "          self.info.append((count,count+len_seq))\n",
    "          count += len_seq\n",
    "\n",
    "      self.padded = np.vstack(self.padded)\n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
    "        scores = []\n",
    "\n",
    "        predictions = self.model.predict(self.padded,verbose=0)\n",
    "\n",
    "        # para cada secuencia de validación\n",
    "        for start,end in self.info:\n",
    "\n",
    "          # en `probs` iremos guardando las probabilidades de los términos target\n",
    "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
    "\n",
    "          # calculamos la perplejidad por medio de logaritmos\n",
    "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
    "\n",
    "        # promediamos todos los scores e imprimimos el valor promedio\n",
    "        current_score = np.mean(scores)\n",
    "        history_ppl.append(current_score)\n",
    "        print(f'\\n mean perplexity: {current_score} \\n')\n",
    "\n",
    "        # chequeamos si tenemos que detener el entrenamiento\n",
    "        if current_score < self.min_score:\n",
    "          self.min_score = current_score\n",
    "          self.model.save(\"my_model.keras\")\n",
    "          print(\"Saved new model!\")\n",
    "          self.patience_counter = 0\n",
    "        else:\n",
    "          self.patience_counter += 1\n",
    "          if self.patience_counter == self.patience:\n",
    "            print(\"Stopping training...\")\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "483ac43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - loss: 3.1765\n",
      " mean perplexity: 15.5859956741333 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m996s\u001b[0m 4s/step - loss: 3.0113\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - loss: 2.5021\n",
      " mean perplexity: 11.917875289916992 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m985s\u001b[0m 4s/step - loss: 2.3740\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - loss: 2.1532\n",
      " mean perplexity: 11.465410232543945 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m848s\u001b[0m 4s/step - loss: 2.1163\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - loss: 2.0212\n",
      " mean perplexity: 11.546177864074707 \n",
      "\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1022s\u001b[0m 5s/step - loss: 1.9929\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - loss: 1.9161\n",
      " mean perplexity: 11.442464828491211 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1437s\u001b[0m 6s/step - loss: 1.8914\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - loss: 1.8252\n",
      " mean perplexity: 13.4536771774292 \n",
      "\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1480s\u001b[0m 7s/step - loss: 1.8041\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - loss: 1.7450\n",
      " mean perplexity: 14.82399845123291 \n",
      "\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1459s\u001b[0m 7s/step - loss: 1.7261\n",
      "Epoch 8/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - loss: 1.6735\n",
      " mean perplexity: 14.028059005737305 \n",
      "\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1493s\u001b[0m 7s/step - loss: 1.6551\n",
      "Epoch 9/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - loss: 1.6077\n",
      " mean perplexity: 18.28924560546875 \n",
      "\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1545s\u001b[0m 7s/step - loss: 1.5919\n",
      "Epoch 10/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - loss: 1.5456\n",
      " mean perplexity: 20.493600845336914 \n",
      "\n",
      "Stopping training...\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1541s\u001b[0m 7s/step - loss: 1.5335\n"
     ]
    }
   ],
   "source": [
    "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
    "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
    "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
    "history_ppl = []\n",
    "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl)], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c1abb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(history_ppl) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aa24d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
    "model = keras.models.load_model('my_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3702b77d",
   "metadata": {},
   "source": [
    "### Generación de secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a55b4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(model, seed_text, max_length, n_words):\n",
    "    \"\"\"\n",
    "        Exec model sequence prediction\n",
    "\n",
    "        Args:\n",
    "            model (keras): modelo entrenado\n",
    "            seed_text (string): texto de entrada (input_seq)\n",
    "            max_length (int): máxima longitud de la sequencia de entrada\n",
    "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
    "        returns:\n",
    "            output_text (string): sentencia con las \"n_words\" agregadas\n",
    "    \"\"\"\n",
    "    output_text = seed_text\n",
    "\t# generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "\t\t# Encodeamos\n",
    "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
    "\t\t# Si tienen distinto largo\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "\n",
    "\t\t# Predicción softmax\n",
    "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
    "\t\t# Vamos concatenando las predicciones\n",
    "        out_word = ''\n",
    "\n",
    "        out_word = idx2char[y_hat]\n",
    "\n",
    "\t\t# Agrego las palabras a la frase predicha\n",
    "        output_text += out_word\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1f326c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'los hermanos\\r\\ny al conta el conta el canta'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text='los hermanos'\n",
    "\n",
    "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb97a922",
   "metadata": {},
   "source": [
    "###  Beam search y muestreo aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ce08c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcionalidades para hacer encoding y decoding\n",
    "def encode(text,max_length=max_context_size):\n",
    "\n",
    "    encoded = [char2idx[ch] for ch in text]\n",
    "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "\n",
    "    return encoded\n",
    "\n",
    "def decode(seq):\n",
    "    return ''.join([idx2char[ch] for ch in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b41d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "# función que selecciona candidatos para el beam search\n",
    "def select_candidates(\n",
    "    pred, num_beams, vocab_size, history_probs, history_tokens, temp, mode\n",
    "):\n",
    "\n",
    "    # colectar todas las probabilidades para la siguiente búsqueda\n",
    "    pred_large = []\n",
    "\n",
    "    for idx, pp in enumerate(pred):\n",
    "        pred_large.extend(np.log(pp + 1e-10) + history_probs[idx])\n",
    "\n",
    "    pred_large = np.array(pred_large)\n",
    "\n",
    "    # criterio de selección\n",
    "    if mode == \"det\":\n",
    "        idx_select = np.argsort(pred_large)[::-1][\n",
    "            :num_beams\n",
    "        ]  # beam search determinista\n",
    "    elif mode == \"sto\":\n",
    "        idx_select = np.random.choice(\n",
    "            np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large / temp)\n",
    "        )  # beam search con muestreo aleatorio / estocastico\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Wrong selection mode. {mode} was given. det and sto are supported.\"\n",
    "        )\n",
    "\n",
    "    # traducir a índices de token en el vocabulario\n",
    "    new_history_tokens = np.concatenate(\n",
    "        (\n",
    "            np.array(history_tokens)[idx_select // vocab_size],\n",
    "            np.array([idx_select % vocab_size]).T,\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
    "    return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
    "\n",
    "\n",
    "def beam_search(model, num_beams, num_words, input, temp=1, mode=\"det\"):\n",
    "\n",
    "    # first iteration\n",
    "\n",
    "    # encode\n",
    "    encoded = encode(input)\n",
    "\n",
    "    # first prediction\n",
    "    y_hat = model.predict(encoded, verbose=0)[0, -1, :]\n",
    "\n",
    "    # get vocabulary size\n",
    "    vocab_size = y_hat.shape[0]\n",
    "\n",
    "    # initialize history\n",
    "    history_probs = [0] * num_beams\n",
    "    history_tokens = [encoded[0]] * num_beams\n",
    "\n",
    "    # select num_beams candidates\n",
    "    history_probs, history_tokens = select_candidates(\n",
    "        [y_hat], num_beams, vocab_size, history_probs, history_tokens, temp, mode\n",
    "    )\n",
    "\n",
    "    # beam search loop\n",
    "    for i in range(num_words - 1):\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        for hist in history_tokens:\n",
    "\n",
    "            # actualizar secuencia de tokens\n",
    "            input_update = np.array([hist[i + 1 :]]).copy()\n",
    "\n",
    "            # predicción\n",
    "            y_hat = model.predict(input_update, verbose=0)[0, -1, :]\n",
    "\n",
    "            preds.append(y_hat)\n",
    "\n",
    "        history_probs, history_tokens = select_candidates(\n",
    "            preds, num_beams, vocab_size, history_probs, history_tokens, temp, mode\n",
    "        )\n",
    "\n",
    "    return history_tokens[:, -(len(input) + num_words) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd5c570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicción con beam search\n",
    "salidas = beam_search(model, num_beams=10, num_words=20, input=\"los hermanos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9399dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 43, 48, 33, 38, 29,  4, 12, 24, 50, 43, 48, 11,  3,  9, 51, 29,\n",
       "       33, 50, 43, 33, 38, 24, 21, 15, 24, 33,  9, 51, 29, 33, 29])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salidas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2765aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'los hermanos\\r\\nque no había que e'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veamos las salidas\n",
    "decode(salidas[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
